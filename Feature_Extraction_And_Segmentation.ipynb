{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Always make all imports in the first cell of the notebook, run them all once.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from skimage.util import img_as_float   \n",
    "from skimage.filters import gabor_kernel\n",
    "from skimage.filters import sobel\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.util import invert\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import img_as_ubyte\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from heapq import *\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "from random import randint\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IAM_Crop(gray_img, bin_img):\n",
    "        \"\"\"\n",
    "        Detects the bounding box of the handwritten paragraph of the given IAM form image\n",
    "        and returns a cropped image of it.\n",
    "        :param gray_img:    the IAM form image to be processed.\n",
    "        :param bin_img:     binarized IAM form image to be processed.\n",
    "        :return:            cropped gray and binary images of the handwritten paragraph.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get image dimensions.\n",
    "        height, width = gray_img.shape\n",
    "\n",
    "        # Find all contours in the page.\n",
    "        contours, hierarchy = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Minimum contour width to be considered as the black separator line.\n",
    "        threshold_width =1000\n",
    "        line_offset = 10\n",
    "\n",
    "        # Page paragraph boundaries.\n",
    "        up, down, left, right = 0, height - 1, 0, width - 1\n",
    "\n",
    "        # Detect the main horizontal black separator lines of the IAM handwriting forms.\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            if w < threshold_width:\n",
    "                continue\n",
    "\n",
    "            if y < height // 2:\n",
    "                up = max(up, y + h + line_offset)\n",
    "            else:\n",
    "                down = min(down, y - line_offset)\n",
    "\n",
    "        # Apply erosion to remove noise and dots.\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        eroded_img = cv2.erode(bin_img, kernel, iterations=2)\n",
    "        gray_img = cv2.erode(gray_img, kernel, iterations=2)\n",
    "\n",
    "        # Get horizontal and vertical histograms.\n",
    "        hor_hist = np.sum(eroded_img, axis=1) / 255\n",
    "        ver_hist = np.sum(eroded_img, axis=0) / 255\n",
    "\n",
    "        # Detect paragraph white padding.\n",
    "        while left < right and ver_hist[left] == 0:\n",
    "            left += 1\n",
    "        while right > left and ver_hist[right] == 0:\n",
    "            right -= 1\n",
    "        while up < down and hor_hist[up] == 0:\n",
    "            up += 1\n",
    "        while down > up and hor_hist[down] == 0:\n",
    "            down -= 2\n",
    "\n",
    "        up-=50\n",
    "        left-=50\n",
    "        right+=50\n",
    "        # Crop images.\n",
    "        gray_img = gray_img[up:down + 1, left:right + 1]\n",
    "        bin_img=bin_img[up:down + 1, left:right + 1]\n",
    "\n",
    "        # Return the handwritten paragraph\n",
    "        return gray_img,bin_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_projections(sobel_image):\n",
    "    return np.sum(sobel_image, axis=1)  \n",
    "\n",
    "\n",
    "\n",
    "def find_peak_regions(hpp, divider=2):\n",
    "    threshold = (np.max(hpp)-np.min(hpp))/divider\n",
    "    peaks = []\n",
    "    peaks_index = []\n",
    "    for i, hppv in enumerate(hpp):\n",
    "        if hppv < threshold:\n",
    "            peaks.append([i, hppv])\n",
    "    return peaks\n",
    "\n",
    "def get_hpp_walking_regions(peaks_index):\n",
    "    hpp_clusters = []\n",
    "    cluster = []\n",
    "    for index, value in enumerate(peaks_index):\n",
    "        cluster.append(value)\n",
    "\n",
    "        if index < len(peaks_index)-1 and peaks_index[index+1] - value > 1:\n",
    "            hpp_clusters.append(cluster)\n",
    "            cluster = []\n",
    "\n",
    "        #get the last cluster\n",
    "        if index == len(peaks_index)-1:\n",
    "            hpp_clusters.append(cluster)\n",
    "            cluster = []\n",
    "            \n",
    "    return hpp_clusters\n",
    "\n",
    "#sobel_image = sobel(img)\n",
    "##hpp = horizontal_projections(sobel_image)\n",
    "#plt.plot(hpp)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(a, b):\n",
    "    return (b[0] - a[0]) ** 2 + (b[1] - a[1]) ** 2\n",
    "\n",
    "def astar(array, start, goal):\n",
    "\n",
    "    neighbors = [(0,1),(0,-1),(1,0),(-1,0),(1,1),(1,-1),(-1,1),(-1,-1)]\n",
    "    close_set = set()\n",
    "    came_from = {}\n",
    "    gscore = {start:0}\n",
    "    fscore = {start:heuristic(start, goal)}\n",
    "    oheap = []\n",
    "\n",
    "    heappush(oheap, (fscore[start], start))\n",
    "    \n",
    "    while oheap:\n",
    "\n",
    "        current = heappop(oheap)[1]\n",
    "\n",
    "        if current == goal:\n",
    "            data = []\n",
    "            while current in came_from:\n",
    "                data.append(current)\n",
    "                current = came_from[current]\n",
    "            return data\n",
    "\n",
    "        close_set.add(current)\n",
    "        for i, j in neighbors:\n",
    "            neighbor = current[0] + i, current[1] + j            \n",
    "            tentative_g_score = gscore[current] + heuristic(current, neighbor)\n",
    "            if 0 <= neighbor[0] < array.shape[0]:\n",
    "                if 0 <= neighbor[1] < array.shape[1]:                \n",
    "                    if array[neighbor[0]][neighbor[1]] == 1:\n",
    "                        continue\n",
    "                else:\n",
    "                    # array bound y walls\n",
    "                    continue\n",
    "            else:\n",
    "                # array bound x walls\n",
    "                continue\n",
    "                \n",
    "            if neighbor in close_set and tentative_g_score >= gscore.get(neighbor, 0):\n",
    "                continue\n",
    "                \n",
    "            if  tentative_g_score < gscore.get(neighbor, 0) or neighbor not in [i[1]for i in oheap]:\n",
    "                came_from[neighbor] = current\n",
    "                gscore[neighbor] = tentative_g_score\n",
    "                fscore[neighbor] = tentative_g_score + heuristic(neighbor, goal)\n",
    "                heappush(oheap, (fscore[neighbor], neighbor))\n",
    "                \n",
    "    return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scan the paths to see if there are any blockers.\n",
    "\n",
    "def get_binary(img):\n",
    "    mean = np.mean(img)\n",
    "    if mean == 0.0 or mean == 1.0:\n",
    "        return img\n",
    "\n",
    "    thresh = threshold_otsu(img)\n",
    "    binary = img <= thresh\n",
    "    binary = binary*1\n",
    "    return binary\n",
    "\n",
    "def path_exists(window_image):\n",
    "    #very basic check first then proceed to A* check\n",
    "    if 0 in horizontal_projections(window_image):\n",
    "        return True\n",
    "    \n",
    "    padded_window = np.zeros((window_image.shape[0],1))\n",
    "    world_map = np.hstack((padded_window, np.hstack((window_image,padded_window)) ) )\n",
    "    path = np.array(astar(world_map, (int(world_map.shape[0]/2), 0), (int(world_map.shape[0]/2), world_map.shape[1])))\n",
    "    if len(path) > 0:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_road_block_regions(nmap):\n",
    "    road_blocks = []\n",
    "    needtobreak = False\n",
    "    \n",
    "    for col in range(nmap.shape[1]):\n",
    "        start = col\n",
    "        end = col+20\n",
    "        if end > nmap.shape[1]-1:\n",
    "            end = nmap.shape[1]-1\n",
    "            needtobreak = True\n",
    "\n",
    "        if path_exists(nmap[:, start:end]) == False:\n",
    "            road_blocks.append(col)\n",
    "\n",
    "        if needtobreak == True:\n",
    "            break\n",
    "            \n",
    "    return road_blocks\n",
    "\n",
    "def group_the_road_blocks(road_blocks):\n",
    "    #group the road blocks\n",
    "    road_blocks_cluster_groups = []\n",
    "    road_blocks_cluster = []\n",
    "    size = len(road_blocks)\n",
    "    for index, value in enumerate(road_blocks):\n",
    "        road_blocks_cluster.append(value)\n",
    "        if index < size-1 and (road_blocks[index+1] - road_blocks[index]) > 1:\n",
    "            road_blocks_cluster_groups.append([road_blocks_cluster[0], road_blocks_cluster[len(road_blocks_cluster)-1]])\n",
    "            road_blocks_cluster = []\n",
    "\n",
    "        if index == size-1 and len(road_blocks_cluster) > 0:\n",
    "            road_blocks_cluster_groups.append([road_blocks_cluster[0], road_blocks_cluster[len(road_blocks_cluster)-1]])\n",
    "            road_blocks_cluster = []\n",
    "\n",
    "    return road_blocks_cluster_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_line_from_image(image, lower_line, upper_line):\n",
    "    lower_boundary = np.min(lower_line[:, 0])\n",
    "    upper_boundary = np.max(upper_line[:, 0])\n",
    "    img_copy = np.copy(image)\n",
    "    r, c = img_copy.shape\n",
    "    for index in range(c-1):\n",
    "        img_copy[lower_line[index, 0]:0, index] = 255\n",
    "        img_copy[r:upper_line[index, 0], index] = 255\n",
    "    \n",
    "    return img_copy[lower_boundary:upper_boundary, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Segment(imgpath):\n",
    "   \n",
    "    path = imgpath\n",
    "\n",
    "    imgStar = rgb2gray(imread(path))\n",
    "    imgStar = img_as_ubyte(imgStar)\n",
    "    imgStar=cv2.resize(imgStar, (0,0), fx=0.6, fy=0.6) \n",
    "    l_padding = 10\n",
    "    r_padding = 10 \n",
    "    gray_img = imgStar[:, l_padding:-r_padding]\n",
    "    thresh, bin_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    img,bin_img = IAM_Crop(gray_img,bin_img)\n",
    "\n",
    "    img = np.invert(bin_img)\n",
    "\n",
    "\n",
    "\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Gray Image After PreProcessing\")\n",
    "    plt.show()\n",
    "    # img = gray_img\n",
    "    \n",
    "    sobel_image = sobel(img)\n",
    "    hpp = horizontal_projections(sobel_image)\n",
    "    #print (np.max(hpp))\n",
    "\n",
    "    peaks = find_peak_regions(hpp)\n",
    "\n",
    "    peaks_index = np.array(peaks)[:,0].astype(int)\n",
    "    count=0\n",
    "    segmented_img = np.copy(img)\n",
    "    r,c = segmented_img.shape\n",
    "    for ri in range(r):\n",
    "        if ri in peaks_index:\n",
    "            segmented_img[ri, :] = 0\n",
    "        \n",
    "    hpp_clusters = get_hpp_walking_regions(peaks_index)\n",
    "    binary_image = get_binary(img)\n",
    "\n",
    "    for cluster_of_interest in hpp_clusters:\n",
    "        nmap = binary_image[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:]\n",
    "        if len(cluster_of_interest)==1:\n",
    "            continue\n",
    "        road_blocks = get_road_block_regions(nmap)\n",
    "        road_blocks_cluster_groups = group_the_road_blocks(road_blocks)\n",
    "        #create the doorways\n",
    "        for index, road_blocks in enumerate(road_blocks_cluster_groups):\n",
    "            window_image = nmap[:, road_blocks[0]: road_blocks[1]+10]\n",
    "            binary_image[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:][:, road_blocks[0]: road_blocks[1]+10][int(window_image.shape[0]/2),:] *= 0\n",
    "\n",
    "    #now that everything is cleaner, its time to segment all the lines using the A* algorithm\n",
    "    line_segments = []\n",
    "    for i, cluster_of_interest in enumerate(hpp_clusters):\n",
    "        nmap = binary_image[cluster_of_interest[0]:cluster_of_interest[len(cluster_of_interest)-1],:]\n",
    "        path = np.array(astar(nmap, (int(nmap.shape[0]/2), 0), (int(nmap.shape[0]/2),nmap.shape[1]-1)))\n",
    "        if path.shape == (0,):\n",
    "            continue\n",
    "        if i==len(hpp_clusters)-1:\n",
    "            break\n",
    "        offset_from_top = cluster_of_interest[0]\n",
    "        path[:,0] += offset_from_top\n",
    "        line_segments.append(path)\n",
    "\n",
    "\n",
    "   \n",
    "   \n",
    "      ## add an extra line to the line segments array which represents the last bottom row on the image\n",
    "    last_bottom_row = np.flip(np.column_stack(((np.ones((img.shape[1],))*img.shape[0]), np.arange(img.shape[1]))).astype(int), axis=0)\n",
    "    line_segments.append(last_bottom_row)\n",
    "\n",
    "    line_images=[]\n",
    "    line_count = len(line_segments)\n",
    "    #fig, ax = plt.subplots(figsize=(10,10), nrows=line_count-1)\n",
    "    for line_index in range(line_count-1):\n",
    "        line_image = extract_line_from_image(img, line_segments[line_index], line_segments[line_index+1])\n",
    "        line_images.append(line_image)\n",
    "       # ax[line_index].imshow(line_image, cmap=\"gray\")\n",
    "\n",
    "    binary=[]    \n",
    "    for i in range(0,len(line_images)):\n",
    "        first_line = line_images[i]\n",
    "        thresh = threshold_otsu(first_line)\n",
    "        binary.append(first_line > thresh)\n",
    "\n",
    "\n",
    "\n",
    "    # find the vertical projection by adding up the values of all pixels along rows\n",
    "    # vertical_projection = np.sum(binary, axis=0)\n",
    "\n",
    "    # plot the vertical projects\n",
    "    return binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disk_kernel(imgg,loops):\n",
    "    slopes=[0,0,0]\n",
    "    arr = np.zeros((loops,2)) #logA(d)-log(d) and log(d)\n",
    "    for i in range(0,loops):\n",
    "        d = 2*i+1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(d,d))        #ndimage.rotate(img, 45) for ellipse\n",
    "        img_dilation = cv2.erode(np.uint8(imgg), kernel, iterations=1)\n",
    "        #totalPixels = img_dilation.shape[0]*img_dilation.shape[1]\n",
    "        Area = cv2.countNonZero(img_dilation)                              ##count white pixels\n",
    "        arr[i] = (np.log(Area)- np.log(d) , np.log(d))                     #/(Area + cv2.countNonZero(img_dilation))\n",
    "\n",
    "\n",
    "\n",
    "    min = 1000\n",
    "\n",
    "    for x in range(1,loops-2):\n",
    "        for y in range(x+2,loops-1):\n",
    "            line1 = arr[0:x +1] \n",
    "            line2 = arr[x:y +1]\n",
    "            line3 = arr[y:loops]\n",
    "        \n",
    "            slope1,_,_,_,std1 = stats.linregress(line1[:,0], line1[:,1])\n",
    "            slope2,_,_,_,std2 = stats.linregress(line2[:,0], line2[:,1])\n",
    "            slope3,_,_,_,std3 = stats.linregress(line3[:,0], line3[:,1])\n",
    "        \n",
    "            if(min > std1+std2+std3):\n",
    "                min = std1+std2+std3\n",
    "                slopes=[slope1,slope2,slope3]\n",
    "   # slopes.append(slope1)\n",
    "    #slopes.append(slope2)\n",
    "    #slopes.append(slope3)\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_kernel(imgg,loops,rotation):\n",
    "    slopes=[0,0,0]\n",
    "    arr2= np.zeros((loops,2))\n",
    "    for i in range(0,loops):\n",
    "        d = 2*i+1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(2*d,d))\n",
    "        kernel=ndi.rotate(kernel, rotation) \n",
    "        img_dilation = cv2.erode(np.uint8(imgg), kernel, iterations=1)\n",
    "        Area = cv2.countNonZero(img_dilation)                              ##count white pixels\n",
    "        arr2[i] = (np.log(Area)- np.log(d) , np.log(d))                     #/(Area + cv2.countNonZero(img_dilation))\n",
    "        \n",
    "    min = 1000\n",
    "\n",
    "    for x in range(1,loops-2):\n",
    "        for y in range(x+2,loops-1):\n",
    "            line1 = arr2[0:x +1] \n",
    "            line2 = arr2[x:y +1]\n",
    "            line3 = arr2[y:loops]\n",
    "        \n",
    "            slope1,_,_,_,std1 = stats.linregress(line1[:,0], line1[:,1])\n",
    "            slope2,_,_,_,std2 = stats.linregress(line2[:,0], line2[:,1])\n",
    "            slope3,_,_,_,std3 = stats.linregress(line3[:,0], line3[:,1])\n",
    "        \n",
    "            if(min > std1+std2+std3):\n",
    "                min = std1+std2+std3\n",
    "                slopes=[slope1,slope2,slope3]\n",
    "   # slopes.append(slope1)\n",
    "    #slopes.append(slope2)\n",
    "    #slopes.append(slope3)\n",
    "    return slopes\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start of project #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Extraction():\n",
    "    data = pd.read_csv(\"data.csv\") \n",
    "    ######################## randomly choose 7 images for the model and testing###############################################\n",
    "    classes = random.sample(range(0, 350), 3)\n",
    "    class1 = data[data[\"writer-id\"] == classes[0]]\n",
    "    class2 = data[data[\"writer-id\"] == classes[1]]\n",
    "    class3 = data[data[\"writer-id\"] == classes[2]]\n",
    "\n",
    "    while(len(class1)<4 or len(class2)<3 or len(class3)<3):\n",
    "        classes = random.sample(range(0, 350), 3)\n",
    "        class1 = data[data[\"writer-id\"] == classes[0]]\n",
    "        class2 = data[data[\"writer-id\"] == classes[1]]\n",
    "        class3 = data[data[\"writer-id\"] == classes[2]]\n",
    "\n",
    "    one = np.array(class1)\n",
    "    two = np.array(class2)\n",
    "    three = np.array(class3)\n",
    "\n",
    "    images1 = random.sample(range(0, len(class1)-1), 3)\n",
    "    images2 = random.sample(range(0, len(class2)-1), 2)\n",
    "    images3 = random.sample(range(0, len(class3)-1), 2)\n",
    "    \n",
    "    image01=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+one[0][0]+'.png')   #class 1\n",
    "    print('1-done')\n",
    "    image02=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+one[1][0]+'.png')\n",
    "    print('2-done')\n",
    "    image11=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+two[0][0]+'.png')\n",
    "    print('3-done')\n",
    "    image12=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+two[1][0]+'.png')   #class 2\n",
    "    print('4-done')\n",
    "\n",
    "    image21=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+three[0][0]+'.png') #class 3\n",
    "    print('5-done')\n",
    "    image22=Segment('C:/Users/Lenovo/Desktop/formsA-D/'+three[1][0]+'.png')\n",
    "    print('6-done')\n",
    "    \n",
    "    images = []\n",
    "    images.append(image01)\n",
    "    images.append(image02)\n",
    "    images.append(image11)\n",
    "    images.append(image12)\n",
    "    images.append(image21)\n",
    "    images.append(image22)\n",
    "    \n",
    "    Y_List = []\n",
    "    Y_classes = [classes[0],classes[0],classes[1],classes[1],classes[2],classes[2]]\n",
    "    Y_test = classes[0]\n",
    "    test_image = one[2][0]\n",
    "    \n",
    "    for i in range(0,len(images)):\n",
    "        for x in range(0, len(images[i])):\n",
    "            Y_List.append(Y_classes[i])\n",
    "\n",
    "    Y_train = np.array(Y_List)\n",
    "    ####################################\n",
    "    gradientsList = []\n",
    "    for j in range(0, len(images)):\n",
    "        for i in range(0, len(images[j])):\n",
    "            slopes = disk_kernel(images[j][i],20)\n",
    "            gradients = []\n",
    "            gradients.append(slopes[0])\n",
    "            gradients.append(slopes[1])\n",
    "            gradients.append(slopes[2])\n",
    "            rotation=0\n",
    "            for x in range (0,18):\n",
    "                slopes = (ellipse_kernel(images[j][i],20,rotation))\n",
    "                gradients.append(slopes[0])\n",
    "                gradients.append(slopes[1])\n",
    "                gradients.append(slopes[2])\n",
    "                rotation+=10\n",
    "            gradientsList.append(gradients)\n",
    "        print('1-fetures done')\n",
    "    X_train = np.array(gradientsList)\n",
    "    \n",
    "    return X_train, Y_train, test_image, Y_test\n",
    "    ####t=np.count_nonzero(np.isnan(X_train))\n",
    "\n",
    "# print(\"--------------------\")\n",
    "# print(one[0][0])\n",
    "# print(one[1][0])\n",
    "# print(one[2][0])\n",
    "# print(two[0][0])\n",
    "# print(two[1][0])\n",
    "# print(three[0][0])\n",
    "# print(three[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image01=Segment('G:/imgs/'+one[0][0]+'.png')   #class 1\n",
    "# image02=Segment('G:/imgs/'+one[1][0]+'.png')\n",
    "\n",
    "# image11=Segment('G:/imgs/'+two[0][0]+'.png')\n",
    "# image12=Segment('G:/imgs/'+two[1][0]+'.png')   #class 2\n",
    "\n",
    "# image21=Segment('G:/imgs/'+three[0][0]+'.png') #class 3\n",
    "# image22=Segment('G:/imgs/'+three[1][0]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# images.append(image01)\n",
    "# images.append(image02)\n",
    "# images.append(image11)\n",
    "# images.append(image12)\n",
    "# images.append(image21)\n",
    "# images.append(image22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_List = []\n",
    "# Y_classes = [classes[0],classes[0],classes[1],classes[1],classes[2],classes[2]]\n",
    "# Y_actual = classes[0]\n",
    "# for i in range(0,len(images)):\n",
    "#     for x in range(0, len(images[i])):\n",
    "#         Y_List.append(Y_classes[i])\n",
    "\n",
    "# Y_train = np.array(Y_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradientsList = []\n",
    "# for j in range(0, len(images)):\n",
    "#     for i in range(0, len(images[j])):\n",
    "#         slopes = disk_kernel(images[j][i],20)\n",
    "#         gradients = []\n",
    "#         gradients.append(slopes[0])\n",
    "#         gradients.append(slopes[1])\n",
    "#         gradients.append(slopes[2])\n",
    "#         rotation=0\n",
    "#         for x in range (0,18):\n",
    "#             slopes = (ellipse_kernel(images[j][i],20,rotation))\n",
    "#             gradients.append(slopes[0])\n",
    "#             gradients.append(slopes[1])\n",
    "#             gradients.append(slopes[2])\n",
    "#             rotation+=10\n",
    "#         gradientsList.append(gradients)\n",
    "        \n",
    "#print(np.array(gradientsList).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(gradientsList)\n",
    "# print(X_train)\n",
    "# t=np.count_nonzero(np.isnan(X_train))\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train.shape)\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X_train, Y_train, X_test):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "    KNN.fit(X_train, Y_train)\n",
    "\n",
    "    imagesTest = []\n",
    "    imagesTest.append(Segment('C:/Users/Lenovo/Desktop/formsA-D/'+X_test+'.png')) #test sample\n",
    "\n",
    "    gradientsList = []\n",
    "    for j in range(0, len(imagesTest)):\n",
    "        for i in range(0, len(imagesTest[j])):\n",
    "            slopes = disk_kernel(imagesTest[j][i],20)\n",
    "            gradients = []\n",
    "            gradients.append(slopes[0])\n",
    "            gradients.append(slopes[1])\n",
    "            gradients.append(slopes[2])\n",
    "            rotation=0\n",
    "            for x in range (0,18):\n",
    "                slopes = (ellipse_kernel(imagesTest[j][i],20,rotation))\n",
    "                gradients.append(slopes[0])\n",
    "                gradients.append(slopes[1])\n",
    "                gradients.append(slopes[2])\n",
    "                rotation+=10\n",
    "            gradientsList.append(gradients)\n",
    "\n",
    "    X_test = np.array(gradientsList)\n",
    "    ###########################################\n",
    "\n",
    "    Y_predict = KNN.predict(X_test)\n",
    "    #result = np.bincount(Y_predict)\n",
    "    return Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = 0\n",
    "\n",
    "# # try:\n",
    "  \n",
    "# X_train, Y_train, test_image, Y_actual = Feature_Extraction()\n",
    "# result = testing(X_train, Y_train, test_image)\n",
    "# maximum=np.bincount(result).argmax()\n",
    "\n",
    "# # except:\n",
    "# #     maximum=randint(1, 3)\n",
    "\n",
    "# print(Y_actual)\n",
    "# print(maximum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = 0\n",
    "for i in range(0,10):\n",
    "    print(i)\n",
    "    try:\n",
    "    \n",
    "        X_train, Y_train, test_image, Y_actual = Feature_Extraction()\n",
    "        result = testing(X_train, Y_train, test_image)\n",
    "        maximum=np.bincount(result).argmax()\n",
    "\n",
    "    except:\n",
    "        maximum=randint(1, 3)\n",
    "\n",
    "    print(Y_actual)\n",
    "    print(maximum)\n",
    "    if(Y_actual==maximum):\n",
    "        accuracy+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((accuracy/9)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
